[{"body":"","link":"https://example.org/","section":"","title":"Lerian Studio Blog"},{"body":"lorem ipsum\n","link":"https://example.org/about/","section":"","title":"About"},{"body":"no mundo da tecnologia financeira, construir sistemas robustos, escaláveis e confiáveis é fundamental. os ledgers financeiros, em particular, requerem considerações de arquitetura para garantir que possam lidar com transações complexas, mantendo a integridade dos dados e o desempenho. neste artigo, exploraremos como o command query responsibility segregation (cqrs) e a event-driven architecture (eda) podem ser combinados para criar sistemas financeiros poderosos, usando nosso ledger financeiro de código aberto, midaz, como estudo de caso.\nnota: deixarei os diagramas em \u0026lsquo;mermaid\u0026rsquo; caso queiram visualizar.\ngraph TD subgraph \u0026#34;cqrs + eda architecture\u0026#34; subgraph \u0026#34;client layer\u0026#34; UI[ui/api clients] end subgraph \u0026#34;api layer\u0026#34; API[api gateway] end subgraph \u0026#34;command layer\u0026#34; CMD[command handlers] VAL[validators] end subgraph \u0026#34;event bus\u0026#34; EB[rabbitmq] end subgraph \u0026#34;domain layer\u0026#34; DOM[domain logic] end subgraph \u0026#34;persistence\u0026#34; WRTDB[(write database)] RDDB[(read database)] end subgraph \u0026#34;query layer\u0026#34; QRY[query handlers] VM[view models] end UI --\u0026gt; API API --\u0026gt; CMD API --\u0026gt; QRY CMD --\u0026gt; VAL CMD --\u0026gt; DOM DOM --\u0026gt; WRTDB DOM --\u0026gt; EB EB --\u0026gt; VM VM --\u0026gt; RDDB QRY --\u0026gt; RDDB end classDef client fill:#9FA8DA,color:black; classDef api fill:#7986CB,color:white; classDef command fill:#5C6BC0,color:white; classDef domain fill:#3F51B5,color:white; classDef eventbus fill:#8BC34A,color:black; classDef storage fill:#FFB74D,color:black; classDef query fill:#FF8A65,color:black; class UI client; class API api; class CMD,VAL command; class DOM domain; class EB eventbus; class WRTDB,RDDB storage; class QRY,VM query; o desafio dos sistemas financeiros sistemas financeiros apresentam desafios únicos que arquiteturas monolíticas tradicionais têm dificuldade em resolver:\nalto volume de transações: sistemas financeiros devem processar milhares, senão milhões/bilhões, de transações diariamente regras de negócio complexas: transações financeiras envolvem regras complexas, validações e cálculos consistência de dados: os dados financeiros devem permanecer consistentes em múltiplas operações requisitos de auditoria: cada operação financeira deve ser rastreável e auditável preocupações com escalabilidade: o sistema deve escalar para lidar com volumes crescentes de transações, de maneira a não comprometer a sua integridade, ao mesmo tempo mantendo a questão de custo em voga esses desafios exigem padrões de design de software que possam separar responsabilidades, escalar independentemente e manter a integridade dos dados. é aqui que o cqrs e a arquitetura orientada a eventos entram em cena.\nentendendo o cqrs em sistemas financeiros command query responsibility segregation (cqrs) é um padrão de design que separa operações de leitura e escrita em modelos distintos. em um contexto financeiro, essa separação é particularmente valiosa.\nsequenceDiagram participant Client participant API as api gateway participant CH as command handler participant DB as write database participant EB as event bus participant QH as query handler participant RDB as read database Client-\u0026gt;\u0026gt;API: POST /transactions API-\u0026gt;\u0026gt;CH: CreateTransactionCommand CH-\u0026gt;\u0026gt;DB: Save Transaction CH-\u0026gt;\u0026gt;EB: Publish TransactionCreatedEvent EB--\u0026gt;\u0026gt;RDB: Update Read Model Client-\u0026gt;\u0026gt;API: GET /transactions/{id} API-\u0026gt;\u0026gt;QH: GetTransactionQuery QH-\u0026gt;\u0026gt;RDB: Fetch Transaction DTO QH--\u0026gt;\u0026gt;API: Transaction Details API--\u0026gt;\u0026gt;Client: Transaction Response o lado do command (write model) o lado do command lida com operações que mudam o estado do sistema, como:\ncriar novas contas registrar transações financeiras atualizar saldos modificar informações de ativos no midaz, nossos serviços de command são estruturados com responsabilidades claras e focadas:\n// de components/onboarding/internal/services/command/command.go type UseCase struct { OrganizationRepo organization.Repository LedgerRepo ledger.Repository SegmentRepo segment.Repository PortfolioRepo portfolio.Repository AccountRepo account.Repository AssetRepo asset.Repository MetadataRepo mongodb.Repository RabbitMQRepo rabbitmq.ProducerRepository RedisRepo redis.RedisRepository } cada operação de command é isolada em seu próprio arquivo com uma única responsabilidade - nota: algo que inclusive facilita, e muito, a leitura e manutenção do código. por exemplo, criando uma nova conta em create-account.go:\n// simplificado de create-account.go func (uc *UseCase) CreateAccount(ctx context.Context, req *account.Account) (*account.Account, error) { // validar entrada // gerar ID único // armazenar no repositório // publicar evento // retornar resultado } o lado do query (read model) o lado do query se concentra em recuperar e apresentar dados:\nbuscar informações de contas recuperar histórico de transações gerar relatórios ler saldos no midaz, os serviços de query são estruturados de forma semelhante, mas otimizados para leitura:\n// de components/onboarding/internal/services/query/query.go type UseCase struct { OrganizationRepo organization.Repository LedgerRepo ledger.Repository SegmentRepo segment.Repository PortfolioRepo portfolio.Repository AccountRepo account.Repository AssetRepo asset.Repository MetadataRepo mongodb.Repository RedisRepo redis.RedisRepository } as operações de query também são isoladas em arquivos dedicados, como buscar detalhes de uma conta em get-id-account.go:\n// simplificado de get-id-account.go func (uc *UseCase) GetIDAccount(ctx context.Context, id uuid.UUID) (*account.Account, error) { // buscar do repositório // transformar se necessário // retornar dados } benefícios do cqrs em sistemas financeiros performance optimization: write models e read models podem ser otimizados independentemente. para sistemas financeiros com muito mais leituras do que escritas (usuários verificando saldos versus fazendo transações), isso é crucial. nossa implementação de queries demonstra essa otimização\nscalability: commands e queries podem escalar separadamente. durante períodos de alto volume (como processos financeiros de final de mês ou fim de ano), os serviços de query podem ser escalados sem afetar o processamento de transações. isso é facilitado por nossa infraestrutura de contêineres\nspecialized data storage: commands podem usar armazenamento otimizado para operações de escrita (como postgresql), enquanto queries podem usar armazenamento otimizado para leitura (como mongodb para consulta flexível de metadados)\nreduced complexity: ao separar concerns, a domain logic complexa em operações financeiras torna-se mais gerenciável, reduzindo bugs e melhorando a manutenibilidade, como pode ser visto em nosso transaction domain\nevent-driven architecture em sistemas financeiros enquanto o cqrs aborda muitos desafios, sistemas financeiros também se beneficiam de loose coupling e processamento assíncrono. é aqui que a event-driven architecture (eda) se destaca.\ngraph TD subgraph \u0026#34;financial transaction\u0026#34; TX[transaction creation] --\u0026gt;|publishes| E1[TransactionCreatedEvent] E1 --\u0026gt;|consumed by| P1[balance processor] E1 --\u0026gt;|consumed by| P2[notification processor] E1 --\u0026gt;|consumed by| P3[audit service] P1 --\u0026gt;|publishes| E2[BalanceUpdatedEvent] E2 --\u0026gt;|consumed by| P4[reporting service] E2 --\u0026gt;|consumed by| P5[customer notification] P3 --\u0026gt;|publishes| E3[AuditRecordEvent] E3 --\u0026gt;|consumed by| P6[regulatory compliance] end classDef command fill:#4CAF50,color:white; classDef event fill:#FF9800,color:white; classDef processor fill:#2196F3,color:white; class TX command; class E1,E2,E3 event; class P1,P2,P3,P4,P5,P6 processor; conceitos principais de eda no contexto financeiro events as facts: cada evento financeiro (transação criada, saldo atualizado, etc.) é registrado como um fato imutável asynchronous processing: operações que não exigem respostas imediatas podem ser processadas de forma assíncrona, melhorando o desempenho e a experiência do usuário decoupled services: serviços se comunicam através de eventos, reduzindo dependências diretas o transaction flow command initiation: um command é recebido para criar uma transação (por exemplo, transferir fundos entre contas) validation and processing: o command handler valida a transação, cria os registros necessários e publica um evento asynchronous effects: event handlers processam os efeitos da transação de forma assíncrona: atualizando saldos de contas criando registros de operação gerando logs de auditoria read model updates: uma vez que os efeitos estão completos, os read models são atualizados, tornando as mudanças visíveis para queries a technical architecture nossos serviços são estruturados para suportar este fluxo:\napi layer: endpoints http recebem commands e queries, documentados em nossa api swagger command/query services: serviços separados lidam com as respectivas operações em components/transaction/internal/services event bus: rabbitmq fornece reliable message delivery entre serviços storage layer: postgresql para dados transacionais estruturados mongodb para armazenamento flexível de metadados redis para dados efêmeros como idempotency keys distributed transactions um dos desafios em sistemas financeiros é manter a consistência entre operações distribuídas. no midaz, lidamos com isso através de:\neventual consistency: a maioria das operações não requer consistência imediata, permitindo-nos usar processamento assíncrono via rabbitmq optimistic concurrency: quando conflitos podem ocorrer, usamos version tracking para detectá-los e tratá-los, como implementado em nossos data models compensating actions: para falhas em processos de múltiplas etapas, implementamos compensating actions para manter a consistência geral através dos event consumers benefícios no mundo real e lições aprendidas a implementação de cqrs e eda no midaz trouxe vários benefícios significativos que têm impactado diretamente a qualidade, manutenibilidade e eficiência do nosso sistema financeiro.\nbenefícios tangíveis melhor desempenho: ao separar preocupações de leitura e escrita, otimizamos cada caminho para seus requisitos específicos. nossos serviços de query são especializados para recuperar dados com alta eficiência, enquanto os serviços de command são projetados para garantir a integridade dos dados durante as operações de escrita. na prática, isso nos permitiu:\nreduzir o tempo de resposta para consultas frequentes em até 60% aumentar o throughput de transações em períodos de pico eliminar contenções de recursos entre operações de leitura e escrita melhor escalabilidade: serviços podem escalar independentemente com base em seus padrões de carga. isso foi particularmente valioso durante:\nperíodos de fechamento financeiro mensal, quando a frequência de consultas aumenta significativamente processamentos em lote de transações, que podem ser escalados horizontalmente sem afetar os serviços de consulta expansão para novos mercados, permitindo-nos aumentar seletivamente a capacidade de serviços específicos nossa configuração de infraestrutura facilita essa escalabilidade independente.\nconfiabilidade aprimorada: processamento assíncrono e operações idempotentes reduzem o impacto de falhas temporárias. nosso mecanismo de idempotência garante que transações não sejam duplicadas, mesmo em caso de retentativas, enquanto nosso sistema de mensageria assíncrona permite:\nrecuperação graceful após falhas em componentes resiliência contra indisponibilidade temporária de serviços processamento consistente mesmo durante picos de carga evolução mais fácil: serviços desacoplados nos permitem evoluir diferentes partes do sistema independentemente. nossa experiência prática demonstrou que:\nnovas funcionalidades podem ser adicionadas aos serviços de transaction sem afetar os serviços de onboarding atualizações de esquema em um modelo (leitura ou escrita) podem ser realizadas sem impactar o outro novas versões de apis podem ser lançadas gradualmente, mantendo compatibilidade com versões anteriores auditabilidade aprimorada: um benefício não antecipado inicialmente foi a excelente rastreabilidade proporcionada por nossa arquitetura orientada a eventos. cada mudança de estado é registrada como um evento, facilitando:\nreconstrução do histórico completo de transações atendimento a requisitos regulatórios de auditoria financeira análise de causa-raiz em cenários de inconsistência de dados nossa implementação de logs de transações demonstra esse compromisso com a auditabilidade.\nlições valiosas aprendidas trade-off de complexidade: cqrs e eda adicionam complexidade que deve ser justificada pelos benefícios. aprendemos que:\na separação de modelos não é necessária para todas as entidades do domínio. entidades com baixa taxa de mudança e consulta simples podem usar um modelo unificado a complexidade adicional exige investimento em documentação clara e treinamento da equipe. nosso CONTRIBUTING.md e STRUCTURE.md foram criados para facilitar esse processo ferramentas de observabilidade são essenciais para entender o fluxo de dados em um sistema distribuído. investimos em integração com grafana para monitoramento desafios de consistência eventual: as equipes precisam projetar uis e experiências que levem em conta a consistência eventual. isso incluiu:\ndesenvolver padrões de ux para comunicar estados temporários aos usuários implementar mecanismos de polling e notificação para atualizar a interface quando dados são modificados educar stakeholders sobre os trade-offs entre consistência forte e disponibilidade criar mecanismos de sincronização para casos críticos onde a consistência imediata é necessária importância do monitoramento: sistemas distribuídos orientados a eventos requerem monitoramento e rastreamento abrangentes. para isso:\nimplementamos rastreamento distribuído em todo o sistema usando opentelemetry, como visto em nossos serviços de command criamos dashboards especializados para visualizar fluxos de eventos e filas estabelecemos alertas para detectar anomalias em padrões de consumo de eventos introduzimos correlação de ids entre serviços para facilitar o rastreamento de transações completas estratégias de teste: testar sistemas orientados a eventos requer abordagens diferentes das aplicações monolíticas tradicionais. nosso aprendizado incluiu:\ndesenvolver testes de integração que simulam o fluxo completo de eventos criar mocks de produtores e consumidores para testar componentes isoladamente implementar testes que verificam a idempotência e a resiliência a falhas utilizar golden files para validar a consistência dos resultados equilibrando inovação técnica e valor de negócio: uma lição fundamental foi a importância de alinhar decisões de design com necessidades reais de negócio:\nnem todas as partes do sistema precisam da mesma sofisticação técnica iniciar com componentes críticos para o negócio e evoluir incrementalmente medir o impacto real das otimizações em métricas de negócio, como tempo de processamento de transações e disponibilidade do sistema envolver stakeholders não-técnicos na compreensão dos trade-offs da arquitetura adotada casos de uso reais para ilustrar o impacto prático dessas escolhas de design, destacamos alguns casos de uso reais onde cqrs e eda provaram seu valor:\nprocessamento de transações de alta frequência: o sistema consegue processar milhões de transações por minuto, com cada transação seguindo o fluxo de validação, processamento assíncrono e atualização consistente de saldos geração de relatórios em tempo real: mesmo durante períodos de alto volume transacional, os usuários conseguem gerar relatórios complexos sem impactar o desempenho do sistema de processamento recuperação de falhas: durante eventos de indisponibilidade de componentes, o sistema consegue retomar o processamento sem perda de dados, graças aos mecanismos de persistência de eventos e idempotência implementados no consumer rabbitmq conclusão cqrs e arquitetura orientada a eventos fornecem padrões poderosos para construir sistemas financeiros robustos. ao separar preocupações de leitura e escrita e aproveitar o processamento assíncrono, esses padrões permitem ledgers financeiros escaláveis, confiáveis e de fácil manutenção.\nno midaz, vimos como esses padrões podem ser aplicados para criar uma plataforma financeira flexível que lida com transações complexas, mantendo o desempenho e a integridade dos dados. a combinação de cqrs e eda provou ser especialmente valiosa para problemas do domínio financeiro, onde consistência de dados, requisitos de auditoria e regras de negócio complexas convergem.\nà medida que a tecnologia financeira continua a evoluir, padrões de design como esses se tornarão ferramentas cada vez mais importantes na caixa de ferramentas do desenvolvedor para construir a próxima geração de sistemas financeiros.\n","link":"https://example.org/posts/construindo-um-financial-ledger-cqrs-eda/","section":"posts","title":"construindo um financial ledger com cqrs e eda"},{"body":"no mundo dos sistemas financeiros, o gerenciamento eficiente e seguro de dados de clientes é um requisito fundamental. o plugin crm do midaz foi desenvolvido especificamente para atender essa necessidade, oferecendo uma solução robusta e flexível para instituições financeiras de todos os portes.\ndecisões arquiteturais plugin versus microservice a decisão de implementar o crm como um plugin, ao invés de um microservice tradicional, foi baseada em diversos fatores:\nacoplamento controlado:\ncomo plugin: interface bem definida com o core, mas mantendo acoplamento necessário para operações críticas como microservice: independência total, mas com overhead de comunicação e complexidade de deployment decisão: plugin oferece melhor equilíbrio entre independência e integração deployment simplificado:\ncomo plugin: deployment único com o core, reduzindo complexidade operacional como microservice: deployment independente, mas com necessidade de gerenciar múltiplos serviços decisão: modelo de plugin reduz overhead operacional mantendo flexibilidade performance:\ncomo plugin: comunicação mais eficiente com o core, reduzindo latência como microservice: latência adicional devido à comunicação via rede decisão: plugin oferece melhor performance para operações críticas mongodb versus alternativas a escolha do mongodb como storage principal foi resultado de uma análise detalhada:\nmodelo de dados:\nmongodb: schema flexível, ideal para metadata dinâmica e evolução do modelo postgresql: schema rígido, melhor para dados altamente estruturados decisão: flexibilidade do mongodb mais adequada para necessidades variadas dos clientes performance:\nmongodb: excelente performance em leitura, especialmente com índices compostos postgresql: melhor para joins complexos e transações acid decisão: padrão de acesso do crm favorece mongodb (mais leituras que escritas) escalabilidade:\nmongodb: sharding nativo, replicação simplificada postgresql: requer mais configuração para sharding decisão: mongodb oferece caminho mais claro para escalabilidade decisões de segurança criptografia e hashing a implementação de segurança foi cuidadosamente planejada:\nalgoritmo de criptografia:\naes-gcm: oferece authenticated encryption, garantindo confidencialidade e integridade alternativas consideradas: aes-cbc (mais simples, mas sem autenticação integrada) decisão: aes-gcm oferece melhor segurança sem comprometer performance estratégia de hashing:\nhmac-sha256: permite busca eficiente mantendo segurança alternativas: bcrypt (mais lento, inadequado para busca) decisão: hmac-sha256 ideal para nosso caso de uso de busca segura armazenamento de chaves:\nambiente de desenvolvimento: variáveis de ambiente produção: integração com key management services decisão: flexibilidade para diferentes ambientes design de apis rest versus graphql optamos por uma api rest pelos seguintes motivos:\nmaturidade:\nrest: ecossistema maduro, ferramentas estabelecidas graphql: mais flexível, mas requer mais setup decisão: rest mais adequado para nosso caso de uso caching:\nrest: caching nativo http graphql: requer implementação customizada decisão: benefício do caching http para performance documentação:\nrest: swagger/openapi bem estabelecido graphql: schema introspection, mas menos ferramentas decisão: ecossistema swagger facilita adoção design de endpoints estruturamos os endpoints considerando:\ngranularidade:\nendpoints específicos para cada operação evitamos endpoints genéricos demais decisão: melhor controle de permissões e performance versionamento:\nurl versioning (/v1/\u0026hellip;) alternativas: header versioning, content negotiation decisão: simplicidade e clareza para desenvolvedores estratégia de dados metadata flexível o sistema de metadata foi um ponto crucial:\nestrutura:\nflat key-value: simples, fácil de indexar nested objects: mais flexível, mas complexo decisão: flat key-value pela simplicidade e performance validação:\ntipos básicos: string, number, boolean tamanho máximo: 2000 caracteres por default decisão: equilíbrio entre flexibilidade e controle soft delete implementamos soft delete considerando:\nbenefícios:\nauditoria completa recuperação de dados manutenção de histórico trade-offs:\nmaior consumo de storage queries mais complexas decisão: benefícios superam custos integração com ecossistema autenticação e autorização a integração com o plugin de auth foi planejada para:\ncontrole de acesso:\nbaseado em roles permissões granulares decisão: flexibilidade para diferentes modelos de negócio auditoria:\nlog centralizado rastreabilidade completa decisão: compliance e segurança performance e monitoramento estratégia de cache implementamos uma estratégia de cache em múltiplas camadas:\napplication cache:\ndados frequentemente acessados cache de configurações decisão: redução de latência database cache:\níndices otimizados query planning decisão: performance em escala health checks sistema robusto de health checks:\ncomponentes monitorados: conexão com mongodb integração com auth api endpoints decisão: detecção rápida de problemas conclusão o plugin crm do midaz é resultado de decisões técnicas cuidadosamente pensadas, sempre considerando:\nnecessidades reais dos clientes requisitos de segurança performance e escalabilidade facilidade de manutenção cada escolha técnica foi feita visando o equilíbrio entre funcionalidade, segurança e usabilidade, resultando em uma solução que atende às necessidades complexas de instituições financeiras modernas.\nquer saber mais sobre como implementar o plugin crm em seu ambiente? confira nossa documentação técnica ou entre em contato com nossa equipe de suporte.\n","link":"https://example.org/posts/gerenciando-dados-de-clientes-com-o-plugin-crm-do-midaz/","section":"posts","title":"gerenciando dados de clientes com o plugin crm do midaz: segurança e flexibilidade em primeiro lugar"},{"body":"nas últimas semanas, embarcamos em um desafio por aqui: construir a primeira SDK para o Midaz, nosso ledger para core banking (disponível open-source aqui). o que parecia ser um projeto simples \u0026ndash; afinal, openapi documentation e uma infinidade de ferramentas para generation \u0026ndash;, rapidamente se transformou em um rabbit hole técnico bem profundo. colocar a primeira versão em produção trouxe à tona uma discussão fundamental: qual é a fronteira entre as responsabilidades do servidor e do cliente?\nfronteiras de responsabilidade quando começamos a desenvolver a SDK para o Midaz (em Go), a pergunta que constantemente nos perseguia era: até onde a API do backend deve ir e onde começa a responsabilidade de integração/implementação do cliente? ou seja, onde termina o backend e começa o colo do cliente?\nesta pergunta aparentemente simples esconde uma complexidade enorme. tradicionalmente, muitos desenvolvedores consideram que:\nbackend: responsável pela lógica de negócio, persistência, segurança, validações cliente/sdk: responsável apenas por fazer requisições HTTP, serializar/deserializar dados mas será que essa divisão simplista funciona bem na prática? especialmente quando falamos de sistemas financeiros com requisitos rigorosos de consistência, performance e resiliência?\npor que uma sdk robusta importa? durante o desenvolvimento, percebemos que uma sdk financeira precisa ir muito além de simplesmente fazer o wrapping de endpoints REST. ela precisa ser uma camada que:\nprotege o servidor contra inputs inválidos (validação do lado cliente) torna a integração mais resiliente (retries, rate limiting, circuit breaking) oferece performance mesmo em condições adversas (batching, paralelismo) simplifica operações complexas (abstraindo detalhes de implementação) proporciona uma experiência de desenvolvimento fluida (tipos fortemente definidos, erros descritivos) vamos explorar cada um desses aspectos detalhadamente, com exemplos práticos do que implementamos na nossa primeira sdk.\nvalidação no cliente: evitando viagens desnecessárias uma das primeiras decisões que tomamos foi implementar validações robustas no lado cliente. por quê? simples: por que enviar ao servidor uma requisição que sabemos que vai falhar?\n// exemplo de validação de transação financeira no lado cliente func ValidateTransactionDSL(input TransactionDSLValidator) error { if input == nil { return fmt.Errorf(\u0026#34;transaction input cannot be nil\u0026#34;) } // valida código do ativo asset := input.GetAsset() if asset == \u0026#34;\u0026#34; { return fmt.Errorf(\u0026#34;asset code is required\u0026#34;) } if !assetCodePattern.MatchString(asset) { return fmt.Errorf(\u0026#34;invalid asset code format: %s (must be 3-4 uppercase letters)\u0026#34;, asset) } // valida valor if input.GetValue() \u0026lt;= 0 { return fmt.Errorf(\u0026#34;transaction amount must be greater than zero\u0026#34;) } // validações adicionais de contas e consistência... } implementamos validações para:\nformatos de código de ativos (USD, BRL, BTC, Gado, Caixas de Remédio, whatever) montantes e escalas de transações estrutura de contas e operações metadados e payloads auxiliares isso traz múltiplos benefícios:\nfeedback instantâneo para o desenvolvedor redução de latência (evitando roundtrips desnecessários) menor carga no servidor mensagens de erro mais contextualizadas e úteis a validação no cliente não substitui a validação no servidor (que continua essencial por razões de segurança), mas cria uma experiência de desenvolvimento superior e reduz o tráfego de rede.\nresiliência através de retry inteligente sistemas distribuídos falham. esta é uma realidade, não uma possibilidade. quando trabalhamos com operações financeiras, essas falhas são ainda mais críticas e podem ter consequências significativas.\npor isso, implementamos mecanismos sofisticados de retry com exponential backoff:\n// configuração de retry com backoff exponencial client, err := client.New( client.WithAuthToken(\u0026#34;your-auth-token\u0026#34;), client.WithTimeout(30 * time.Second), client.WithRetries(3, 100*time.Millisecond, 1*time.Second), client.UseAllAPIs(), // by the way, isso é um caso a parte aqui: pra que expor o que não precisa ser exposto? ) nosso sistema de retry:\nutiliza backoff exponencial para evitar sobrecarregar servidores em problemas adiciona jitter (variação aleatória) para prevenir thundering herd categoriza erros entre \u0026ldquo;retryable\u0026rdquo; e \u0026ldquo;non-retryable\u0026rdquo; respeita limites de timeout especificados pelo usuário permite personalização completa de estratégias este código parece simples na interface, mas por trás dele há uma implementação robusta que considera diversos cenários de falha:\n// trecho da implementação de retry com backoff func doWithOptions(ctx context.Context, fn func() error, options *Options) error { var err error for attempt := 0; attempt \u0026lt;= options.MaxRetries; attempt++ { // Check if context is done before executing if ctx.Err() != nil { return fmt.Errorf(\u0026#34;operation cancelled: %w\u0026#34;, ctx.Err()) } // Execute the function err = fn() if err == nil { // Success, return immediately return nil } // Check if this is the last attempt if attempt == options.MaxRetries { break } // Check if the error is retryable if !IsRetryableError(err, options) { return err } // Calculate delay with jitter delay := calculateBackoff(attempt, options) delayWithJitter := addJitter(delay, options.JitterFactor) // Wait for the calculated delay or until context is done timer := time.NewTimer(delayWithJitter) select { case \u0026lt;-ctx.Done(): timer.Stop() return fmt.Errorf(\u0026#34;operation cancelled during retry: %w\u0026#34;, ctx.Err()) case \u0026lt;-timer.C: // Continue to next retry attempt } } return fmt.Errorf(\u0026#34;operation failed after %d retries: %w\u0026#34;, options.MaxRetries, err) } Um dos aprendizados mais interessantes foi identificar quais erros deveriam ser tentados novamente e quais não. Por exemplo, erros de validação nunca devem ter retry, enquanto problemas de rede temporários são candidatos ideais. Este modelo de listing by exception é um conceito que foi estudado bastante, e foi aplicado em outras enterprise-grade APIs (exemplo interessante é a da AWS).\n// definição de erros retryable padrão var DefaultRetryableErrors = []string{ \u0026#34;connection reset by peer\u0026#34;, \u0026#34;connection refused\u0026#34;, \u0026#34;timeout\u0026#34;, \u0026#34;deadline exceeded\u0026#34;, \u0026#34;too many requests\u0026#34;, \u0026#34;rate limit\u0026#34;, \u0026#34;service unavailable\u0026#34;, } // códigos HTTP que merecem retry var DefaultRetryableHTTPCodes = []int{ http.StatusRequestTimeout, // 408 http.StatusTooManyRequests, // 429 http.StatusInternalServerError, // 500 http.StatusBadGateway, // 502 http.StatusServiceUnavailable, // 503 http.StatusGatewayTimeout, // 504 } gerenciamento avançado de configurações a modularidade da configuração foi um ponto crítico do design. utilizamos o padrão de opções funcionais (não são 100% fluentes como pede o figurin) para permitir uma configuração limpa e extensível:\n// padrão de options funcionais para configuração flexível client, err := client.New( // configurações básicas client.WithAuthToken(\u0026#34;your-auth-token\u0026#34;), client.WithEnvironment(config.EnvironmentProduction), // opções avançadas de performance client.WithTimeout(30 * time.Second), client.WithRetries(3, 200*time.Millisecond, 2*time.Second), // observabilidade client.WithObservability(true, true, true), // quais APIs utilizar client.UseAllAPIs(), ) este padrão permite:\nconfiguração incremental com defaults sensatos melhor legibilidade e manutenção extensibilidade futura sem quebrar compatibilidade configurações específicas por domínio Além disso, implementamos suporte para configuração via variáveis de ambiente:\n// variáveis de ambiente que o cliente reconhece MIDAZ_AUTH_TOKEN=seu-token // implementaremos a sdk de access management lançada ontem logo logo MIDAZ_ENVIRONMENT=production MIDAZ_ONBOARDING_URL=https://api.exemplo.com/v1 MIDAZ_TRANSACTION_URL=https://transactions.exemplo.com/v1 MIDAZ_DEBUG=true MIDAZ_MAX_RETRIES=5 isso permite uma integração mais suave com diferentes ambientes de deploy, especialmente em contextos de containers e kubernetes.\nperformance otimizada para JSON Em sistemas financeiros, performance não é luxo, é requisito. Um dos pontos de maior otimização foi o processamento JSON, que pode rapidamente se tornar um gargalo:\n// exemplo de nossa implementação de pooling de buffers para JSON type JSONPerformance struct { encoderPool sync.Pool decoderPool sync.Pool bufferPool sync.Pool } func NewJSONPerformance() *JSONPerformance { return \u0026amp;JSONPerformance{ encoderPool: sync.Pool{ New: func() interface{} { return json.NewEncoder(io.Discard) }, }, decoderPool: sync.Pool{ New: func() interface{} { return json.NewDecoder(strings.NewReader(\u0026#34;\u0026#34;)) }, }, bufferPool: sync.Pool{ New: func() interface{} { return new(bytes.Buffer) }, }, } } func (jp *JSONPerformance) Marshal(v interface{}) ([]byte, error) { buf := jp.bufferPool.Get().(*bytes.Buffer) buf.Reset() defer jp.bufferPool.Put(buf) enc := jp.encoderPool.Get().(*json.Encoder) enc.SetEscapeHTML(false) oldWriter := enc.Linter enc.SetWriter(buf) defer func() { enc.SetWriter(oldWriter) jp.encoderPool.Put(enc) }() if err := enc.Encode(v); err != nil { return nil, err } // Copy to avoid returning a reference to the pooled buffer result := make([]byte, buf.Len()) copy(result, buf.Bytes()) return result, nil } Esta abordagem reduziu alocações de memória em nossos benchmarks, principalmente quando fazíamos em conjunto com o pooling de buffers, o que é crucial para sistemas financeiros de alto volume que processam milhões de transações.\npáginação inteligente e universal Lidar com grandes conjuntos de dados é um desafio comum em operações financeiras. Por isso, desenvolvemos um sistema de paginação universal que funciona com diferentes endpoints e paradigmas:\n// interface genérica para qualquer tipo de paginador type Paginator[T any] interface { HasNext() bool Next() (*ListResponse[T], error) Reset() } // exemplo de uso para listar transações com paginação automática paginator := client.Entity.Transactions.GetTransactionPaginator( ctx, \u0026#34;org-id\u0026#34;, \u0026#34;ledger-id\u0026#34;, \u0026amp;models.ListOptions{Limit: 100}, ) totalTransactions := 0 for paginator.HasNext() { page, err := paginator.Next() if err != nil { return err } for _, tx := range page.Items { // processar cada transação processTransaction(tx) totalTransactions++ } } fmt.Printf(\u0026#34;Processadas %d transações no total\\n\u0026#34;, totalTransactions) Nossa implementação suporta:\npáginação por offset/limit (mais comum) páginação por cursor (mais eficiente para grandes datasets) prefetching para melhor performance preservação de filtros e ordenação entre páginas adaptação automática ao tipo de paginação do endpoint concorrência controlada para alto volume Para lidar com os requisitos de alta performance, investimos pesadamente em modelos de concorrência bem controlados:\n// worker pool genérico com controle fino de concorrência func WorkerPool[T, R any]( ctx context.Context, items []T, workFn func(context.Context, T) (R, error), opts ...PoolOption, ) []Result[T, R] { // Config default options := defaultPoolOptions() for _, opt := range opts { opt(options) } resultCh := make(chan Result[T, R], len(items)) var wg sync.WaitGroup // semáforo para controlar concorrência sem := make(chan struct{}, options.workers) // Rate limiter se especificado var limiter \u0026lt;-chan time.Time if options.rateLimit \u0026gt; 0 { ticker := time.NewTicker(time.Second / time.Duration(options.rateLimit)) defer ticker.Stop() limiter = ticker.C } for i, item := range items { // Respeita cancelamento pelo context if ctx.Err() != nil { break } // Rate limiting se ativo if limiter != nil { select { case \u0026lt;-ctx.Done(): break case \u0026lt;-limiter: // Continue quando o rate limiter permitir } } // Adquire slot no semáforo sem \u0026lt;- struct{}{} wg.Add(1) go func(idx int, item T) { defer wg.Done() defer func() { \u0026lt;-sem }() // Libera o semáforo ao final // Cria um timeout interno se necessário execCtx := ctx if options.timeout \u0026gt; 0 { var cancel context.CancelFunc execCtx, cancel = context.WithTimeout(ctx, options.timeout) defer cancel() } // Executa a função de trabalho result, err := workFn(execCtx, item) // Envia o resultado resultCh \u0026lt;- Result[T, R]{ Index: idx, Item: item, Value: result, Error: err, } }(i, item) } // Fecha o canal de resultados quando todo trabalho estiver concluído go func() { wg.Wait() close(resultCh) }() // Coleta resultados var results []Result[T, R] for result := range resultCh { results = append(results, result) } // Ordena resultados se necessário if options.ordered { sort.Slice(results, func(i, j int) bool { return results[i].Index \u0026lt; results[j].Index }) } return results } Esta implementação permite:\nControle preciso de concorrência para evitar sobrecarregar a API Rate limiting para respeitar limites da API Ordenação opcional de resultados Cancelamento gracioso de operações em andamento Timeouts individuais para tarefas tratamento avançado de erros financeiros Em um sistema financeiro, os erros são parte crítica da experiência do desenvolvedor. Investimos em um sistema sofisticado de tratamento de erros:\n// exemplo de uso de erros especializados switch { case errors.IsValidationError(err): // Trata erro de validação fmt.Println(\u0026#34;Erro de validação:\u0026#34;, err) // Extrai erros por campo fieldErrors := errors.GetFieldErrors(err) for _, fieldErr := range fieldErrors { fmt.Printf(\u0026#34;Campo %s: %s\\n\u0026#34;, fieldErr.Field, fieldErr.Message) } case errors.IsInsufficientBalanceError(err): // Trata erro específico financeiro fmt.Println(\u0026#34;Saldo insuficiente:\u0026#34;, err) case errors.IsRateLimitExceededError(err): // Implementa backoff e retry fmt.Println(\u0026#34;Limite de requisições excedido, aguardando:\u0026#34;, err) time.Sleep(exponentialBackoff(attempt)) case errors.IsAuthenticationError(err): // Problema com autenticação fmt.Println(\u0026#34;Erro de autenticação, renovando token:\u0026#34;, err) renewToken() } Adicionalmente, nossos erros incluem:\nCategorização clara (validação, autenticação, rede, etc) Detalhes específicos por domínio financeiro (saldo insuficiente, limites, etc) Códigos de erro e status HTTP associados Sugestões de correção para o desenvolvedor Integração com observabilidade (geração de span de erro) Testes de stress e verificação de escalabilidade Uma característica distintiva da nossa SDK foi o desenvolvimento de uma suite robusta de testes de stress:\n// trecho do código da suite de stress testing func (st *StressTest) Run(ctx context.Context) error { logger := st.observability.GetLogger() logger.Info(\u0026#34;Iniciando teste de stress\u0026#34;, \u0026#34;workers\u0026#34;, st.config.ConcurrentWorkers) // Preparar ambiente de teste if err := st.SetupTestEnvironment(ctx); err != nil { return fmt.Errorf(\u0026#34;falha ao configurar ambiente: %w\u0026#34;, err) } // Executar até interrupção ou duração configurada var wg sync.WaitGroup ctx, cancel := context.WithCancel(ctx) defer cancel() // Inicia monitoramento de métricas st.metrics = NewMetricsCollector(st.observability) go st.metrics.Start(ctx) // Inicia workers para gerar carga for i := 0; i \u0026lt; st.config.ConcurrentWorkers; i++ { wg.Add(1) go func(workerID int) { defer wg.Done() st.runWorker(ctx, workerID) }(i) } // Aguarda conclusão wg.Wait() logger.Info(\u0026#34;Teste de stress concluído\u0026#34;, \u0026#34;transações\u0026#34;, st.metrics.TotalTransactions()) return nil } Esta suite nos permitiu:\nValidar o comportamento sob carga extrema (50.000+ tx/s ou modelos de 1:1 em conta com 10000+ tx/s) Identificar e corrigir bottlenecks antes do lançamento Verificar o comportamento de mecanismos de retry e resiliência Testar a degradação graceful sob falhas parciais Validar limites de recursos (memória, CPU, conexões, e o próprio sistema distribuído) No ponto específico de validar limites de recursos e do sistema distribuído, utilizamos o pumba para simular cenários de caos (em docker), e isso nos ajudou a identificar pontos interessantes na implementação do próprio backend.\ndocumentação direcionada por exemplos Percebemos que bons exemplos são mais valiosos que documentação abstrata. Por isso, demos ênfase especial a exemplos práticos:\n// exemplo completo de transferência entre contas func ExampleTransferBetweenAccounts() { // Inicializar cliente c, err := client.New( client.WithAuthToken(os.Getenv(\u0026#34;MIDAZ_TOKEN\u0026#34;)), client.UseAllAPIs(), ) if err != nil { log.Fatalf(\u0026#34;Erro inicializando cliente: %v\u0026#34;, err) } // Definir detalhes da transação input := \u0026amp;models.TransactionDSLInput{ Description: \u0026#34;Transferência para pagamento de aluguel\u0026#34;, Send: \u0026amp;models.DSLSend{ Asset: \u0026#34;BRL\u0026#34;, Value: 150000, // R$ 1.500,00 Scale: 2, Source: \u0026amp;models.DSLSource{ From: []models.DSLFromTo{ { Account: \u0026#34;conta-origem-123\u0026#34;, Amount: \u0026amp;models.DSLAmount{ Asset: \u0026#34;BRL\u0026#34;, Value: 150000, Scale: 2, }, }, }, }, Distribute: \u0026amp;models.DSLDistribute{ To: []models.DSLFromTo{ { Account: \u0026#34;conta-destino-456\u0026#34;, Amount: \u0026amp;models.DSLAmount{ Asset: \u0026#34;BRL\u0026#34;, Value: 150000, Scale: 2, }, }, }, }, }, Metadata: map[string]any{ \u0026#34;referencia\u0026#34;: \u0026#34;aluguel-julho-2025\u0026#34;, \u0026#34;categoria\u0026#34;: \u0026#34;moradia\u0026#34;, }, } // Executar a transação tx, err := c.Entity.Transactions.CreateTransactionWithDSL( context.Background(), \u0026#34;org-exemplo\u0026#34;, \u0026#34;ledger-principal\u0026#34;, input, ) if err != nil { log.Fatalf(\u0026#34;Erro na transferência: %v\u0026#34;, err) } fmt.Printf(\u0026#34;Transferência realizada com sucesso! ID: %s\\n\u0026#34;, tx.ID) } Cada exemplo está acompanhado de comentários detalhados e cobrimos todos os cenários principais:\nCriação de entidades (organizações, contas, etc) Operações financeiras (transferências, depósitos, saques) Consultas e relatórios (balanços, extratos, histórico) Workflows completos (onboarding, transações) A vantagem da unificação de interface Falando um pouco sobre a vantagem de unificar múltiplas APIs de backend sob uma interface coerente: no mundo financeiro, frequentemente temos APIs separadas para diferentes domínios:\nAPI de onboarding (organizações, contas) API de transactions (transferências, saldos) API de compliance (KYC, AML) API de reporting (relatórios, extratos) etc etc etc Cada uma com suas peculiaridades e convenções. Nossa SDK unifica todas sob uma única interface consistente:\n// Mesmo padrão para todas as APIs, independente do backend // API de onboarding organization, err := client.Entity.Organizations.CreateOrganization(ctx, input) // API de transactions transaction, err := client.Entity.Transactions.CreateTransaction(ctx, orgID, ledgerID, input) // API de balanços balance, err := client.Entity.Accounts.GetBalance(ctx, orgID, ledgerID, accountID) Esta unificação traz benefícios significativos para o desenvolvedor em si:\nReduz a curva de aprendizado para novos desenvolvedores Abstrai as diferenças de implementação entre serviços Permite evolução independente do backend e frontend Facilita migração entre diferentes versões de APIs A discussão sobre fronteiras: o que aprendemos Voltando à questão inicial sobre as fronteiras de responsabilidade entre servidor e cliente, concluímos que a resposta não é binária. Em vez disso, é um espectro que depende do contexto:\nValidação: tanto cliente quanto servidor devem validar - cliente para UX e DevEx, servidor para segurança Resiliência: principalmente responsabilidade do cliente, com suporte do servidor (idempotência, o que nossa API também trata com uma option específica de WithIdempotency()) Performance: responsabilidade compartilhada, com otimizações específicas em cada lado Domínio: o servidor define o modelo, mas o cliente pode enriquecê-lo com abstrações úteis O que ficou claro é que SDKs não são meros wrappers de API - elas são produtos completos que precisam considerar toda a experiência do desenvolvedor e os requisitos específicos do domínio.\ntrade-offs e desafios de design importantes Durante o desenvolvimento da SDK, nos confrontamos com vários trade-offs importantes que impactam diretamente desenvolvedores e usuários:\nValidação no cliente vs. sincronização com o servidor A implementação de validações robustas no cliente traz benefícios claros de performance e experiência do desenvolvedor, mas também introduz um desafio: // Se estas regras de validação mudam no servidor... if !assetCodePattern.MatchString(asset) { return fmt.Errorf(\u0026#34;invalid asset code format: %s (must be 3-4 uppercase letters)\u0026#34;, asset) } Este é um trade-off significativo:\nVantagem: redução de latência e feedback instantâneo Desvantagem: potencial divergência entre regras cliente/servidor se os clientes não atualizarem a SDK Nossa solução foi documentar claramente a necessidade de atualizações regulares e fornecer testes que ajudam a detectar divergências de validação, além de fazer um robusto linking entre models do cliente e do servidor.\nFilosofia de tratamento de erros: o que tratar automaticamente? Uma decisão crítica foi determinar quais erros a SDK deveria tratar automaticamente versus quais deveriam ser expostos para o backend: // Erros tratados automaticamente pela SDK if errors.IsTemporaryNetworkError(err) || errors.IsRateLimitExceeded(err) { // Aplicar retry automaticamente return retry.Do(ctx, operation) } // Erros que são propagados ao aplicativo if errors.IsBusinessRuleViolation(err) || errors.IsValidationError(err) { // O desenvolvedor precisa tratar estes casos explicitamente return err } Adotamos a filosofia de que:\nErros transientes de infraestrutura/rede são tratados pela SDK\nErros de domínio financeiro ou validação são propagados para permitir tratamento adequado pelo backend\nErros críticos (autenticação, permissões) são propagados com contexto enriquecido para facilitar diagnóstico\nIntegração de observabilidade: o equilíbrio entre intrusão e visibilidade\nA observabilidade é crítica em sistemas financeiros, mas quanto a SDK deve impor versus oferecer como opcional? Aqui é um caso a parte. Remodelamos toda a stack de observabilidade (usando opentelemetry) para que o desenvolvedor possa escolher o que ele quer e o que ele não quer, sem sermos \u0026ldquo;opinionated\u0026rdquo; com relação ao tema \u0026ndash; bem diferente do contexto do midaz open-source, que é mais \u0026ldquo;opinionated\u0026rdquo;.\n// Abordagem não-intrusiva que adotamos: client, err := client.New( // Configuração básica client.WithAuthToken(\u0026#34;token\u0026#34;), // Observabilidade totalmente opcional client.WithObservability( observability.WithTracing(userDefinedTraceProvider), // opcional observability.WithMetrics(userDefinedMeterProvider), // opcional observability.WithLogging(userDefinedLogger), // opcional ), ) Decidimos por uma abordagem modular onde:\nA SDK funciona perfeitamente sem observabilidade configurada\nDesenvolvedores podem injetar seus próprios providers de observabilidade\nFornecemos implementações default para casos simples\nInstrumentamos pontos críticos nas operações financeiras para máxima visibilidade\nOperações Assíncronas e Notificações\nTransações financeiras frequentemente envolvem processos assíncronos. Como a SDK deve lidar com isso?\n// Opção 1: Polling (implementamos inicialmente) status, err := client.Entity.Transactions.GetTransactionStatus(ctx, txID) // Opção 2: Webhooks (planejado para futuro) client.Entity.Transactions.RegisterWebhookHandler(webhookHandler) // Opção 3: Response streaming (planejado para futuro) stream, err := client.Entity.Transactions.WatchTransaction(ctx, txID) for update := range stream.Updates() { // Processar atualizações em tempo real } Nossa abordagem foi evolutiva. Tomamos uma decisão de implementar o básico agora, mas permitindo uma modelagem como a acima exposta:\nComeçamos com polling simples para compatibilidade ampla Adicionaremos suporte a webhooks para notificações em tempo real E planejamos, por fim, streaming de atualizações para casos de uso mais complexos\nestratégia de versionamento e compatibilidade planejado para em breve, dado que estamos na V1 do Midaz O versionamento é um desafio significativo em APIs financeiras que evoluem constantemente:\n// Suporte a múltiplas versões de API client, err := client.New( client.WithAPIVersion(\u0026#34;v1\u0026#34;), // default // ou client.WithAPIVersion(\u0026#34;v2\u0026#34;), // novas funcionalidades ) // Usando feature flags para recursos em preview client.Entity.Transactions.CreateTransaction( ctx, orgID, ledgerID, input, transactions.WithFeatureEnabled(\u0026#34;instant-settlement\u0026#34;), ) Adotaremos uma estratégia de versionamento com múltiplas camadas:\nVersionamento semântico tradicional para a SDK Compatibilidade com múltiplas versões de API em uma única versão da SDK Feature flags para recursos experimentais Aliases de métodos deprecados com warnings para facilitar migrações aprendizados para o futuro Lançar a primeira versão de uma SDK não é o fim da jornada, mas apenas o começo. Já identificamos diversas áreas para evolução:\nEstratégia evolutiva: como evoluir a API sem quebrar compatibilidade? como evoluir o backend sem quebrar compatibilidade? como fazer tudo isso e mantermos o decoupling super necessário entre midaz e midaz-sdk-golang versioning Abstrações de domínio: quais abstrações de nível superior devemos oferecer para simplificar fluxos comuns? que tal evoluirmos para DoWithdrawal, DoDeposit, DoTransfer, etc, fazendo a abstração entre a conta @external/asset e o domínio de transações. que tal evoluirmos para sdk apis 100% fluentes? Balanceamento de responsabilidades: conforme o produto evolui, qual o equilíbrio ideal entre lógica no servidor e no cliente? afinal, não queremos obrigar nossos clientes a usarem a sdk, até pq não conseguiremos manter sdks em um número grande de linguagens Extensibilidade: como permitir que usuários estendam a SDK para seus casos específicos? o fato de sermos open-source facilita isso e chama o público para nos ajudar, mas sabemos da nossa responsabilidade como principais mantenedores do midaz e sua stack Particularmente interessante é a questão dos modelos de domínio. Por exemplo, em vez de apenas oferecer a API para criar uma transação, devemos evoluir para oferecer construções de mais alto nível:\n// Potencial evolução futura - Abstrações de domínio mais ricas // Em vez de apenas criar transações tx, err := client.Entity.Transactions.CreateTransaction(ctx, orgID, ledgerID, createTxInput) // Oferecer fluxos de domínio completos transferResult, err := client.Workflows.DoTransfer(ctx, transferOptions) paymentResult, err := client.Workflows.DoPayment(ctx, paymentOptions) fxResult, err := client.Workflows.DoForeignExchangeTransfer(ctx, fxOptions) o padrão functional options: flexibilidade sem complexidade um padrão de design que merece destaque especial na nossa sdk é o uso extensivo de functional options (ou a implementação parcial de fluent apis). este padrão permite configuração flexível sem comprometer a legibilidade ou simplicidade:\n// definição básica do padrão type ClientOption func(*Client) error func WithTimeout(timeout time.Duration) ClientOption { return func(c *Client) error { if timeout \u0026lt;= 0 { return errors.New(\u0026#34;timeout must be positive\u0026#34;) } c.httpClient.Timeout = timeout return nil } } // uso elegante e extensível client, err := client.New( client.WithAuthToken(\u0026#34;seu-token\u0026#34;), client.WithTimeout(30 * time.Second), client.WithRetries(3), client.WithObservability(true), ) este padrão oferece múltiplas vantagens:\nevita a explosão de construtores para diferentes combinações de opções permite adicionar novos parâmetros sem quebrar código existente facilita testes e configurações condicionais proporciona validação no momento da configuração permite opções compostas que aplicam múltiplas configurações aplicamos o mesmo padrão em diversos níveis da sdk, não apenas na inicialização do cliente:\n// nível de operação - opções específicas por operação tx, err := client.Entity.Transactions.CreateTransaction( ctx, orgID, ledgerID, input, transactions.WithIdempotencyKey(\u0026#34;unique-key-123\u0026#34;), transactions.WithPriority(transactions.PriorityHigh), ) // nível de entidade - configurações por domínio accountSvc := client.Entity.Accounts.WithOptions( accounts.WithCaching(true), accounts.WithValidation(accounts.ValidationStrict), ) conclusão construir a sdk do midaz foi uma jornada de aprendizado e de um estado de flow absurdo. as complexidades de sistemas distribuídos, especialmente no domínio financeiro, e as decisões que tomamos - desde validação robusta no cliente até mecanismos avançados de resiliência e performance - foram todas guiadas pela pergunta: \u0026ldquo;o que tornaria a vida do desenvolvedor mais fácil e o sistema mais confiável?\u0026rdquo;\nno final, a fronteira entre cliente e servidor é mais sobre colaboração do que separação. uma boa sdk não apenas encapsula uma api, mas amplia suas capacidades e protege contra suas limitações.\na gestão cuidadosa dos trade-offs que destacamos - validação no cliente versus sincronização com o servidor, tratamento automático versus exposição de erros, modularidade de observabilidade, e estratégias para operações assíncronas - moldou uma sdk que equilibra simplicidade e poder.\nse você estiver construindo uma sdk, especialmente para sistemas críticos como o financeiro, sugiro considerar cuidadosamente onde colocar essas fronteiras de responsabilidade. sua resposta pode não ser a mesma que a nossa, mas fazer a pergunta já é um excelente começo.\nbora?\npara quem quiser explorar mais, a midaz sdk está disponível em nosso github e inclui extensos exemplos de uso. os exemplos de código e implementações de referência fornecem insights valiosos sobre como implementar padrões robustos em sdks financeiras.\no que você acha? onde você traçaria a linha entre responsabilidades de cliente e servidor em uma sdk? aproveita e dá uma estrelinha pra gente! o midaz está aqui, nosso frontend console está aqui, e nossa sdk está aqui.\nnext steps? port para js. quite a challenge!\nbeijos, fred.\n","link":"https://example.org/posts/licoes-aprendidas-na-construcao-de-uma-sdk-financeira/","section":"posts","title":"lições aprendidas na construção de uma sdk financeira: onde termina o backend e começa o cliente?"},{"body":"","link":"https://example.org/posts/","section":"posts","title":"Posts"},{"body":"","link":"https://example.org/categories/","section":"categories","title":"Categories"},{"body":"","link":"https://example.org/series/","section":"series","title":"Series"},{"body":"","link":"https://example.org/tags/","section":"tags","title":"Tags"}]